# 模型预设配置
# 快速切换常用模型

# ========== AutoGLM 系列 ==========
[autoglm]
MODEL_ID=zai-org/AutoGLM-Phone-9B
SERVED_MODEL_NAME=autoglm-phone-9b
MAX_MODEL_LEN=25480
DTYPE=bfloat16
MODEL_TYPE=multimodal
INSTANCE_TYPE=ml.g6e.xlarge
AWS_REGION=us-east-1

[autoglm-tokyo]
MODEL_ID=zai-org/AutoGLM-Phone-9B
SERVED_MODEL_NAME=autoglm-phone-9b
MAX_MODEL_LEN=25480
DTYPE=bfloat16
MODEL_TYPE=multimodal
INSTANCE_TYPE=ml.g6e.xlarge
AWS_REGION=ap-northeast-1

[autoglm-multilingual]
MODEL_ID=zai-org/AutoGLM-Phone-9B-Multilingual
SERVED_MODEL_NAME=autoglm-multilingual
MAX_MODEL_LEN=25480
DTYPE=bfloat16
MODEL_TYPE=multimodal
INSTANCE_TYPE=ml.g6e.xlarge
AWS_REGION=us-east-1

[autoglm-multilingual-tokyo]
MODEL_ID=zai-org/AutoGLM-Phone-9B-Multilingual
SERVED_MODEL_NAME=autoglm-multilingual
MAX_MODEL_LEN=25480
DTYPE=bfloat16
MODEL_TYPE=multimodal
INSTANCE_TYPE=ml.g6e.xlarge
AWS_REGION=ap-northeast-1

# ========== GLM 系列 ==========
[glm-4.6v-flash]
MODEL_ID=zai-org/GLM-4.6V-Flash
SERVED_MODEL_NAME=glm-4.6v-flash
MAX_MODEL_LEN=8192
DTYPE=bfloat16
MODEL_TYPE=multimodal
INSTANCE_TYPE=ml.g6e.xlarge
AWS_REGION=us-east-1

[glm-4.6v-flash-tokyo]
MODEL_ID=zai-org/GLM-4.6V-Flash
SERVED_MODEL_NAME=glm-4.6v-flash
MAX_MODEL_LEN=8192
DTYPE=bfloat16
MODEL_TYPE=multimodal
INSTANCE_TYPE=ml.g6e.xlarge
AWS_REGION=ap-northeast-1

# ========== Llama 系列 ==========
[llama-3.2-vision]
MODEL_ID=meta-llama/Llama-3.2-11B-Vision-Instruct
SERVED_MODEL_NAME=llama-vision
MAX_MODEL_LEN=8192
DTYPE=bfloat16
MODEL_TYPE=multimodal
INSTANCE_TYPE=ml.g6e.xlarge

[llama-3.2-text]
MODEL_ID=meta-llama/Llama-3.2-3B-Instruct
SERVED_MODEL_NAME=llama-text
MAX_MODEL_LEN=8192
DTYPE=bfloat16
MODEL_TYPE=text
INSTANCE_TYPE=ml.g5.xlarge

# ========== Qwen 系列 ==========
[qwen2.5-7b]
MODEL_ID=Qwen/Qwen2.5-7B-Instruct
SERVED_MODEL_NAME=qwen2.5
MAX_MODEL_LEN=32768
DTYPE=bfloat16
MODEL_TYPE=text
INSTANCE_TYPE=ml.g5.xlarge

[qwen2-vl]
MODEL_ID=Qwen/Qwen2-VL-7B-Instruct
SERVED_MODEL_NAME=qwen2-vl
MAX_MODEL_LEN=8192
DTYPE=bfloat16
MODEL_TYPE=multimodal
INSTANCE_TYPE=ml.g6e.xlarge

# ========== 其他模型 ==========
[mistral-7b]
MODEL_ID=mistralai/Mistral-7B-Instruct-v0.3
SERVED_MODEL_NAME=mistral
MAX_MODEL_LEN=32768
DTYPE=bfloat16
MODEL_TYPE=text
INSTANCE_TYPE=ml.g5.xlarge
